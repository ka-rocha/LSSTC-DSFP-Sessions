{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeeplearningBlank.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Classification with a Multi-layer Perceptron (MLP)\n",
        "\n",
        "In this problem set, we will *not* be implementing neural networks from scratch. Yesterday, you built a *perceptron* in Python. Multi-layer perceptrons (MLPs) are, as discussed in the lecture, several layers of these perceptrons stacked. Here, we will learn how to use one of the most common modules for building neural networks: Pytorch"
      ],
      "metadata": {
        "id": "IUjZTQVbmI-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this module contains our dataset\n",
        "!pip install astronn\n",
        "#this is pytorch, which we will use to build our nn\n",
        "import torch\n",
        "#Standards for plotting, math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#for our objective function\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "YZVxCOpuxNFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 1: Understanding the Data\n",
        "\n",
        "For this problem set, we will use the Galaxy10 dataset made available via the astroNN module. This dataset is made up of 17736 images of galaxies which have been labelled by hand. See this [link](https://astronn.readthedocs.io/en/latest/galaxy10.html) for more information. \n",
        "\n",
        "First we will visualize our data.\n",
        "\n",
        "**Problem 1a** Show one example of each class as an image.\n",
        "\n"
      ],
      "metadata": {
        "id": "xHiDLvC7SvGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from astroNN.datasets import load_galaxy10\n",
        "from astroNN.datasets.galaxy10 import galaxy10cls_lookup\n",
        "%matplotlib inline\n",
        "\n",
        "#helpful functions:\n",
        "#Load the images and labels as numbers\n",
        "images, labels_original = load_galaxy10()\n",
        "\n",
        "#convert numbers to a string\n",
        "galaxy10cls_lookup(labels_original[0])\n"
      ],
      "metadata": {
        "id": "vH8FF-l0TxXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2b** Make a histogram showing the fraction of each class\n",
        "\n",
        "Keep only the top two classes (i.e., the classes with the most galaxies)"
      ],
      "metadata": {
        "id": "dghsBXI3VXcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PoClh9kFVV5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This next block of code converts the data to a format which is more compatible with our neural network."
      ],
      "metadata": {
        "id": "dcZOURvbWWZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_categorical(y, num_classes):\n",
        "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
        "    return np.eye(num_classes, dtype='uint8')[y-1]\n",
        "labels = to_categorical(labels_original, 2)\n",
        "labels = labels.astype(np.float32)\n",
        "images = images.astype(np.float32)\n",
        "images = torch.tensor(images)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# we're going to flatten the images for our MLP\n",
        "images = images.reshape(len(images),-1)"
      ],
      "metadata": {
        "id": "ZdTlL1sTmRbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2c** Split the data into a training and test set (66/33 split) using the train_test_split function from sklearn"
      ],
      "metadata": {
        "id": "WgkfExBpZA_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "CVCTXBKdrCVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next cell will outline how one can make a MLP with pytorch. \n",
        "\n",
        "**Problem 3a** Talk to a partner about how this code works, line by line. Add another hidden layer which is the same size as the first hidden layer. Choose an appropriate final nonlinear layer for this classification problem. Choose the appropriate number of outputs."
      ],
      "metadata": {
        "id": "tIAYeSPhZbQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(torch.nn.Module):\n",
        "      # this defines the model\n",
        "        def __init__(self, input_size, hidden_size):\n",
        "            super(MLP, self).__init__()\n",
        "            self.input_size = input_size\n",
        "            self.hidden_size  = hidden_size\n",
        "            self.hiddenlayer = torch.nn.Linear(self.input_size, self.hidden_size)\n",
        "            self.outputlayer = torch.nn.Linear(self.hidden_size, HOW_MANY_OUTPUTS)\n",
        "            # some nonlinear options\n",
        "            self.sigmoid = torch.nn.Sigmoid()\n",
        "            self.softmax = torch.nn.Softmax()\n",
        "            self.relu = torch.nn.ReLU()\n",
        "        def forward(self, x):\n",
        "            layer1 = self.hiddenlayer(x)\n",
        "            activation = self.sigmoid(layer1)\n",
        "            layer2 = self.outputlayer(activation)\n",
        "            output = self.NONLINEAR(layer2)\n",
        "            return output"
      ],
      "metadata": {
        "id": "u1VUC-2inrVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next block of code will show how one can train the model for 100 epochs. Note that we use the *binary cross-entropy* as our objective function and *stochastic gradient descent* as our optimization method.\n",
        "\n",
        "**Problem 3b** Edit the code so that the function plots the loss for the training and test loss for each epoch."
      ],
      "metadata": {
        "id": "bbDKkusZZ3D8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "def train_model(training_data,training_labels, test_data,test_labels, model):\n",
        "  # define the optimization\n",
        "  criterion = torch.nn.BCELoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=0.1,momentum=0.9)\n",
        "  for epoch in range(100):\n",
        "    # clear the gradient\n",
        "    optimizer.zero_grad()\n",
        "    # compute the model output\n",
        "    myoutput = model(training_data)\n",
        "    # calculate loss\n",
        "    loss = criterion(myoutput, training_labels)\n",
        "    # credit assignment\n",
        "    loss.backward()\n",
        "    # update model weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # ADD PLOT\n"
      ],
      "metadata": {
        "id": "AT8vw_GnxL8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next block trains the code, assuming a hidden layer size of 100 neurons.\n",
        "\n",
        "**Problem 3c** Change the learning rate `lr` to minimize the cross entropy score"
      ],
      "metadata": {
        "id": "E11xxIMWbEz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(np.shape(images_train[0])[0],100)\n",
        "train_model(images_train, labels_train, images_test, labels_test, model)\n"
      ],
      "metadata": {
        "id": "HET50GP4bEJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function called `evaluate_model` which takes the image data, labels and model as input, and the accuracy as output. you can use the `accuracy_score` function."
      ],
      "metadata": {
        "id": "suh_J0qWbOFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "def evaluate_model(data,labels, model):\n",
        "  return(acc)\n",
        "# evaluate the model\n",
        "acc = evaluate_model(images_test,labels_test, model)\n",
        "print('Accuracy: %.3f' % acc)"
      ],
      "metadata": {
        "id": "XM7S2spqSBFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 3d** Make a confusion matrix for the test set using `confusiion_matrix` and 'ConfusionMatrixDisplay`"
      ],
      "metadata": {
        "id": "vQ_KFvIUj-sz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OrnvQDHhkE91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Challenge Problem** Add a third class to your classifier and begin accounting for uneven classes. There are several steps to this:\n",
        "\n",
        "1. Edit the neural network to output 3 classes\n",
        "2. Change the criterion to a *custom criterion* function, such that the entropy of each class is weighted by the inverse fraction of each class size (e.g., if the galaxy class breakdowns are 1:2:3, the weights would be 6:3:2). "
      ],
      "metadata": {
        "id": "A59krpL_iPB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n4amk25yj9J9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}