{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9528a8c2",
   "metadata": {},
   "source": [
    "# Code testing and Continuous Integration\n",
    "\n",
    "We are going to automate testing of our code as part of an example continuous integration development workflow. We'll start by installing pytest, writing or modifying some code to test, and we'll finish by setting up a github actions workflow that will run automatically when we push changes to our repo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde05b36",
   "metadata": {},
   "source": [
    "## Part 0 Installing pytest\n",
    "\n",
    "To install pytest and pytest-coverage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75087415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda3/envs/DSFP\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytest\n",
      "    - pytest-cov\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2022.6.15          |   py38hecd8cb5_0         154 KB\n",
      "    coverage-6.3.2             |   py38hca72f7f_0         244 KB\n",
      "    iniconfig-1.1.1            |     pyhd3eb1b0_0           8 KB\n",
      "    openssl-1.1.1q             |       hca72f7f_0         2.2 MB\n",
      "    pluggy-1.0.0               |   py38hecd8cb5_1          29 KB\n",
      "    py-1.11.0                  |     pyhd3eb1b0_0          76 KB\n",
      "    pytest-7.1.2               |   py38hecd8cb5_0         444 KB\n",
      "    pytest-cov-3.0.0           |     pyhd3eb1b0_0          22 KB\n",
      "    toml-0.10.2                |     pyhd3eb1b0_0          20 KB\n",
      "    tomli-2.0.1                |   py38hecd8cb5_0          25 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  coverage           pkgs/main/osx-64::coverage-6.3.2-py38hca72f7f_0\n",
      "  iniconfig          pkgs/main/noarch::iniconfig-1.1.1-pyhd3eb1b0_0\n",
      "  pluggy             pkgs/main/osx-64::pluggy-1.0.0-py38hecd8cb5_1\n",
      "  py                 pkgs/main/noarch::py-1.11.0-pyhd3eb1b0_0\n",
      "  pytest             pkgs/main/osx-64::pytest-7.1.2-py38hecd8cb5_0\n",
      "  pytest-cov         pkgs/main/noarch::pytest-cov-3.0.0-pyhd3eb1b0_0\n",
      "  toml               pkgs/main/noarch::toml-0.10.2-pyhd3eb1b0_0\n",
      "  tomli              pkgs/main/osx-64::tomli-2.0.1-py38hecd8cb5_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                       2021.7.5-hecd8cb5_1 --> 2022.4.26-hecd8cb5_0\n",
      "  certifi                          2021.5.30-py38hecd8cb5_0 --> 2022.6.15-py38hecd8cb5_0\n",
      "  openssl                                 1.1.1l-h9ed2024_0 --> 1.1.1q-hca72f7f_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "tomli-2.0.1          | 25 KB     | ##################################### | 100% \n",
      "pytest-7.1.2         | 444 KB    | ##################################### | 100% \n",
      "toml-0.10.2          | 20 KB     | ##################################### | 100% \n",
      "pluggy-1.0.0         | 29 KB     | ##################################### | 100% \n",
      "certifi-2022.6.15    | 154 KB    | ##################################### | 100% \n",
      "coverage-6.3.2       | 244 KB    | ##################################### | 100% \n",
      "pytest-cov-3.0.0     | 22 KB     | ##################################### | 100% \n",
      "py-1.11.0            | 76 KB     | ##################################### | 100% \n",
      "iniconfig-1.1.1      | 8 KB      | ##################################### | 100% \n",
      "openssl-1.1.1q       | 2.2 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pytest pytest-cov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5c19ed",
   "metadata": {},
   "source": [
    "## Part 1 Returning to the SDSS Clustering Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6a6d7c",
   "metadata": {},
   "source": [
    "### 1a) Computing statistics of cluster center separation\n",
    "\n",
    "Report the minimum, maximum, and average separation between the centers of the clusters you identified in the introduction to software repositories example. Cluster centers/cores are stored in the \"core_sample_indices_\" attribute of most sklearn clustering objects. \n",
    "\n",
    "You will want this to be done in a modular fashion. First compute the separation distance of the cluster centers. Then write separate functions that return the minimum, maximum, and average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5ff213f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229.61700842607655"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "X = np.load('/Users/kylerocha/Downloads/SDSS_Great_Wall_data.npy')\n",
    "\n",
    "\n",
    "def distance(X):\n",
    "    clustering = DBSCAN(eps=7, min_samples=10)\n",
    "    \n",
    "    preds = clustering.fit_predict(X)\n",
    "    \n",
    "#     plt.scatter( X[:,0], X[:,1], s=0.5, c=preds)\n",
    "#     plt.colorbar()\n",
    "#     plt.show()\n",
    "    \n",
    "    predicted_cluster_ind = preds[ clustering.core_sample_indices_ ]\n",
    "    positions = X[clustering.core_sample_indices_]\n",
    "    \n",
    "#     plt.scatter( positions[:,0], positions[:,1], s=1, c=predicted_cluster_ind )\n",
    "#     plt.show()\n",
    "    \n",
    "    centers = []\n",
    "    for cls in np.unique(predicted_cluster_ind):\n",
    "        locs = np.where(preds == cls)[0]\n",
    "        cluster_center = np.mean( X[locs], axis=0 )\n",
    "        \n",
    "        centers.append( cluster_center )\n",
    "        \n",
    "    centers = np.array(centers)\n",
    "    \n",
    "    distances_between_centers = cdist(centers, centers)\n",
    "    return distances_between_centers\n",
    "\n",
    "out = distance(X)\n",
    "\n",
    "out[4,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1113d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.419506484558392, 490.0921021378237, 194.32842541526801)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def average(distances):\n",
    "    # for every cluster,\n",
    "    max_dist = np.max(distances)\n",
    "    min_dist = np.min(distances[distances>0])\n",
    "    \n",
    "    mean_dist = np.mean(distances[distances>0])\n",
    "    \n",
    "    return  min_dist, max_dist, mean_dist\n",
    "\n",
    "\n",
    "average( distance(X) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c180017",
   "metadata": {},
   "source": [
    "### 1b) Writing a unit test for cluster center separation\n",
    "\n",
    "A good unit test: \n",
    "\n",
    "* Fast\n",
    "* Standalone\n",
    "* Repeatable (deterministic?) \n",
    "* Timely (your test shouldn't take longer than the code to write) \n",
    "\n",
    "For each function you wrote in 2a), write a test function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6dc2eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_distance():\n",
    "    # fill this in\n",
    "    X = np.load('/Users/kylerocha/Downloads/SDSS_Great_Wall_data.npy')\n",
    "\n",
    "    dis = distance(X)\n",
    "    \n",
    "    assert dis[4,9] == 229.61700842607655\n",
    "    \n",
    "test_distance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9251518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_average():\n",
    "    X = np.load('/Users/kylerocha/Downloads/SDSS_Great_Wall_data.npy')\n",
    "    avg = average( distance(X) )\n",
    "    assert avg[-1] == 194.32842541526801\n",
    "    \n",
    "test_average()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f6cff0",
   "metadata": {},
   "source": [
    "## Part 2  Running unit tests in pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb30777",
   "metadata": {},
   "source": [
    "### 2a) Structuring the test file\n",
    "\n",
    "Unfortunately, github actions and pytest require us to convert our jupyter notebooks to python scripts before running CI tests. There are tools to automate this for us, but for now, let's do this by hand. \n",
    "\n",
    "pytest expects your code to be organized according to the following convention - you should have a `file_name.py` and a `test_file_name.py`. Create each. In `file_name.py`, copy the functions for computing cluster distances and statistics. Then, in `test_file_name.py`, copy your unit tests. Be sure to import the methods from `file_name.py` into the test file script. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3655dda4",
   "metadata": {},
   "source": [
    "### 2b) Running the unit test and checking coverage\n",
    "\n",
    "Now to run the unit test - just type `pytest` at the command line of your conda virtual environment. \n",
    "\n",
    "To check the coverage (how well your tests cover your code) type `pytest --cov`\n",
    "\n",
    "If your tests do not achieve full coverage of your code, modify your tests accordingly.\n",
    "\n",
    "If your tests achieve complete coverage and your code passes your tests, move to part 3 below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300c9f9e",
   "metadata": {},
   "source": [
    "### 2c) Bug fixes\n",
    "\n",
    "If your code fails any of your tests, fix your code now and repeat until your code passes your tests. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea7ca4d",
   "metadata": {},
   "source": [
    "## Part 3 Automating Unit Tests with Github Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2d27ec",
   "metadata": {},
   "source": [
    "### Part 3a) Initial Github Actions Workflow template\n",
    "\n",
    "You should find a partially complete github actions workflow template as a .yml file. Github helpfully provides many template workflows for different languages and use cases, so most of the time, you'll just need to fill in the details of an existing workflow. \n",
    "\n",
    "\n",
    "### Part 3b) Fill in when you want the tests to run so that the code runs on a push or pull_request to your working branches and main\n",
    "\n",
    "### Part 3c) make sure that dependencies are properly installed on the virtual machine (\"runner\") that will execute your tests. Up to this point, you should have very minimal dependencies, but for yesterday's SDSS clustering project, you may have more complicated ones. If you have a requirements.txt file in your github directory, you can install dependencies with `pip install -r requirements.txt` - there are many ways to produce a requirements file, but I might start by trying `pip freeze > requirements.txt` within your virtual environment.\n",
    "\n",
    "### Part 3d) Now push to your main branch and check for errors. Fix any that occur. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa06db3",
   "metadata": {},
   "source": [
    "## Part 4 Complete Workflow\n",
    "\n",
    "In this part, work with your partner to adapt yesterday's example clustering problem to the full git collaborative and test-driven workflow. Open Issues for features you want to include, design tests for those features, implement them, make simultaneous changes to the clustering implementation, make push/pull requests, and automate unit testing of your code. Alternatively, get an early start on a problem you might work on in the hackathon by creating a repository, writing some code, and executing unit tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a244dd96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
